{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import salishsea_tools.river_202108 as rivers  # if you want to find river inputs for a different (future?) version of rivers, you'll have to change this the files_between_dates fn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers_list = {'test': [['fraser', 'Fraser'], ['skagit', 'Skagit1']],\n",
    "               'test2': [['fraser', 'Fraser'], ['skagit', 'Skagit1']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "start_str = '20210801'\n",
    "end_str = '20210810'\n",
    "rivers_list = [['fraser', 'Fraser'], ['skagit', 'Skagit1']]\n",
    "source_directory = '/results/forcing/rivers/'\n",
    "save_name = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.strptime(start_str, '%Y%m%d').date()\n",
    "end_date = datetime.strptime(end_str, '%Y%m%d').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_between_dates(start_date, end_date, directory):\n",
    "    files = []\n",
    "    file_dates = []\n",
    "    date_pattern = r'R202108Dailies_y(\\d{4})m(\\d{2})d(\\d{2})'  # regex pattern to specifically match the 202108Dailies - CHANGE IF DIFF VERSION\n",
    "    \n",
    "    for filename in sorted(os.listdir(directory)):\n",
    "        match = re.search(date_pattern, filename)\n",
    "        if match:\n",
    "            year, month, day = map(int, match.groups())\n",
    "            file_date = datetime(year, month, day).date()\n",
    "            if start_date <= file_date <= end_date:\n",
    "                files.append(filename)\n",
    "                file_dates.append(file_date.strftime('%m-%d-%Y'))\n",
    "    \n",
    "    return files, file_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the entire set of rivers and their w_shed/r_call pairs is located in /ocean/cdonaldson/MEOPAR/tools/SalishSeaTools/salishsea_tools/river_202108.py\n",
    "# this fn looks up and returns the river input coordinates and widths\n",
    "def river_bounds(river):\n",
    "\n",
    "    w_shed = river[0]\n",
    "    r_call = river[1]\n",
    "\n",
    "    y = rivers.prop_dict[w_shed][r_call]['i']  # model grid Y-axis\n",
    "    x = rivers.prop_dict[w_shed][r_call]['j']  # model grid X-axis\n",
    "    dy = rivers.prop_dict[w_shed][r_call]['di']  # the number of boxes in Y\n",
    "    dx = rivers.prop_dict[w_shed][r_call]['dj']  # the number of boxes in X\n",
    "\n",
    "    return y, dy, x, dx\n",
    "\n",
    "# when selecting from the big array, do it like [y:y+dy, x:x+dx]\n",
    "# np.array([[1, 2, 3], [4, 5, 6], [7, 8 ,9]])[0:1, 2:3] = array([[3]]), specifies the row then the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_to_timeseries(directory, file_names, rivers):\n",
    "\n",
    "    num_rows = len(file_names)\n",
    "    num_cols = len(rivers)\n",
    "\n",
    "    result = np.zeros((num_rows, num_cols), dtype=float)  # allocate memory based on # days and # rivers\n",
    "\n",
    "    row_idx = 0\n",
    "    col_idx = 0\n",
    "\n",
    "    for file in file_names:\n",
    "        fname = directory + file\n",
    "        ds = xr.open_dataset(fname)\n",
    "        array = ds['rorunoff'].values[0, :, :]  # og shape is (1, 898, 398)\n",
    "\n",
    "        for river in rivers:\n",
    "            y, dy, x, dx = river_bounds(river)\n",
    "            result[row_idx, col_idx] = array[y:y+dy, x:x+dx].sum()  # take the sum in the box, slices are not inclusive\n",
    "            col_idx += 1\n",
    "        \n",
    "        ds.close()  # close the dataset for this day before opening the next one\n",
    "\n",
    "        col_idx = 0  # reset the river idx to loop again\n",
    "        row_idx += 1  # add one to the file idx\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names, file_dates = files_between_dates(start_date, end_date, source_directory)\n",
    "result = files_to_timeseries(source_directory, file_names, rivers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "for i in np.arange(len(rivers_list)):\n",
    "    river_name = rivers_list[i][1] + ' [kg/m2/s]'\n",
    "    data_dict[river_name] = result[:,i]\n",
    "df_data = pd.DataFrame(data_dict)\n",
    "\n",
    "metas = {'filename':file_names, 'date':file_dates}\n",
    "df_metas = pd.DataFrame(metas)\n",
    "\n",
    "df_all = pd.concat([df_metas, df_data], axis=1)\n",
    "# df_all.to_csv('river_dailies_to_ts_{}_{}_{}.csv'.format(save_name, start_str, end_str))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis-cassidy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
