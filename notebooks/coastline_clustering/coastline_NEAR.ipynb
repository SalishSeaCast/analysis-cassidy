{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from salishsea_tools import viz_tools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import cmocean.cm as cm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_202111 = xr.open_dataset('/ocean/cdonaldson/compare_daily_river/SalishSeaCast_day_avg_physics_20190101_20191231.nc')\n",
    "year = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "phys_arr = physics_202111.vosaline.to_numpy()\n",
    "\n",
    "# open the mesh mask and use it to mask the land\n",
    "mesh = xr.open_dataset('../../../../MEOPAR/grid/mesh_mask202108.nc')\n",
    "# the mask is 1 where there is water, we want the opposite.  The meshmask has an extra dimension, hence the [0]\n",
    "tmask = 1 - mesh.tmask[0]\n",
    "tmask = tmask[0:20, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 898, 398)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phys_1d = physics_202111.vosaline[0,:,:,:]\n",
    "phys_1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 898, 398)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Birgit's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask array of grid box thickness based on where there is land (tmask):\n",
    "e3t_mask = np.ma.masked_where((tmask[:,:,:] < 0.1), phys_1d[:,:,:])\n",
    "\n",
    "# find index of grid cell just above the ocean floor by finding the edges for the array along the z-axis:\n",
    "ind = np.array(np.ma.notmasked_edges(e3t_mask[:,:,:], axis=0)) # e3t shape: (z,x,y)\n",
    "\n",
    "# create array of shape (isize, jsize) containing bottom grid cell indices:\n",
    "# index_bottom = ind[1][0][:].reshape(isize,jsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286312,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind[1][0][:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It looks like I can maybe downscale the array first?\n",
    "\n",
    "Tereza's paper describes a method in which stations are selected throughout the SOG, which seems like a pixel-selection method of decreasing resolution. I think I want to do averages to downscale? But I should be careful since I ultimately only want the near-coastline points in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## from ChatGPT, turn this into my own function?\n",
    "\n",
    "# # Create a sample array (replace this with your own data)\n",
    "# original_array = phys_arr[0,0,:,:]\n",
    "\n",
    "# # Define the scale factor (e.g., 2 for halving the dimensions)\n",
    "# scale_factor = 10\n",
    "\n",
    "# # Calculate the new dimensions for the downsampled array\n",
    "# new_height = original_array.shape[0] // scale_factor\n",
    "# new_width = original_array.shape[1] // scale_factor\n",
    "\n",
    "# # Create an empty array for the downsampled result\n",
    "# downsampled_array = np.zeros((new_height, new_width), dtype=original_array.dtype)\n",
    "\n",
    "# # Downscale the array by taking the average of each group of pixels\n",
    "# for y in range(new_height):\n",
    "#     for x in range(new_width):\n",
    "#         y_start = y * scale_factor\n",
    "#         y_end = y_start + scale_factor\n",
    "#         x_start = x * scale_factor\n",
    "#         x_end = x_start + scale_factor\n",
    "#         downsampled_array[y, x] = np.mean(original_array[y_start:y_end, x_start:x_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # Load your matrix as an image (assuming you have NaN values for land)\n",
    "# data_matrix = phys_arr\n",
    "\n",
    "# # Create a binary mask where land (NaN values) are set to 0 and water is set to 255\n",
    "# binary_mask = np.where(np.isnan(data_matrix), 0, 255).astype(np.uint8)\n",
    "\n",
    "# # Find contours in the binary mask\n",
    "# contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# # Assuming you want to extract the outermost contour as the coastline\n",
    "# coastline_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "# # Extract coordinates from the coastline contour\n",
    "# coastline_coordinates = coastline_contour.reshape(-1, 2)\n",
    "\n",
    "# # Now, coastline_coordinates contains the coordinates of the coastline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis-cassidy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
